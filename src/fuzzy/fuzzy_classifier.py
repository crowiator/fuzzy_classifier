# fuzzy_classifier.py
"""
Tento skript implementuje kompletn√Ω pipeline na klasifik√°ciu EKG sign√°lov pomocou fuzzy logiky.
K√≥d zah≈ï≈àa naƒç√≠tanie a pr√≠pravu d√°t, tvorbu fuzzy mno≈æ√≠n, generovanie pravidiel,
vyva≈æovanie datasetu, klasifik√°ciu, a vyhodnotenie modelu pomocou r√¥znych metr√≠k.
"""
import sys
from sklearn.preprocessing import label_binarize
import os
import matplotlib
matplotlib.use('Agg')
import warnings
import numpy as np
import pandas as pd
from collections import defaultdict
from joblib import Parallel, delayed
from sklearn.impute import SimpleImputer
from imblearn.under_sampling import RandomUnderSampler
from imblearn.over_sampling import BorderlineSMOTE
import skfuzzy as fuzz
from sklearn.metrics import classification_report, f1_score, matthews_corrcoef, roc_auc_score
import multiprocessing as mp
from tqdm import tqdm
import matplotlib.pyplot as plt
import pickle
from collections import Counter
from pathlib import Path
from src.config import LEAD, DATA_DIR, FIS_FEATURES, DS2, DS1
from src.feature_extraction.time_domain import extract_beats
from src.feature_extraction.transformer import FeatureExtractor
from src.preprocessing.load import load_record
import seaborn as sns
from sklearn.metrics import confusion_matrix


sys.modules['tkinter'] = None
sys.modules['_tkinter'] = None
os.environ["MPLBACKEND"] = "Agg"
CACHE = Path("cache")
CACHE.mkdir(exist_ok=True)
PLOTS_DIR = Path("plots")
PLOTS_DIR.mkdir(exist_ok=True)
LABELS = ["N", "S", "V", "F"]  # "Q"
IDX2LBL = {i + 1: lbl for i, lbl in enumerate(LABELS)}


def build_ds(rec_ids, tag):
    """
        Naƒç√≠ta a spracuje z√°znamy EKG podƒæa zoznamu identifik√°torov (rec_ids),
        extrahuje pr√≠znaky pre fuzzy klasifik√°ciu a vygeneruje pr√≠slu≈°n√© labely.

        Ak u≈æ existuje cacheovan√Ω .pkl s√∫bor pre dan√Ω tag, naƒç√≠ta sa z disku.

        Args:
            rec_ids (list[str]): Zoznam ID z√°znamov (napr. ['100', '101', ...])
            tag (str): Oznaƒçenie sady (napr. 'ds1' alebo 'ds2') pre cacheovanie

        Returns:
            X (np.ndarray): Pole tvaru (n_samples, n_features) ‚Äì pr√≠znaky
            y (np.ndarray): Pole tvaru (n_samples,) ‚Äì triedy (napr. 'N', 'V', ...)
            features (list[str]): Zoznam pou≈æit√Ωch pr√≠znakov
        """
    # Skontroluj, ƒçi cacheovan√Ω s√∫bor existuje
    pkl_path = CACHE / f"{tag}_traditional.pkl"
    if pkl_path.exists():
        with open(pkl_path, "rb") as f:
            X, y, features = pickle.load(f)
        return X, y, features

    rows, y = [], []

    # Iter√°cia cez v≈°etky z√°znamy (napr. pacientov)
    for rid in tqdm(rec_ids, desc=f"Loading {tag}"):
        # Naƒç√≠taj z√°znam (sign√°l, sampling rate, R-vlny)
        rec = load_record(rid, lead=LEAD, base_dir=DATA_DIR)
        rows.append((rec.signal, rec.fs, rec.r_peaks))
        # Vytvor mapovanie R-vƒ∫n na AAMI labely
        ref = dict(zip(rec.r_peaks, rec.labels_aami))
        # Extrahuj jednotliv√© √∫dery zo sign√°lu (okolo R-vƒ∫n)
        beats = extract_beats(rec.signal, rec.fs, r_idx=rec.r_peaks, clip_extremes=True)
        # Z√≠skaj labely pre ka≈æd√Ω beat podƒæa R_sample, fallback = 'Q'
        y.extend([ref.get(r, "Q") for r in beats["R_sample"]])

    # Inicializuj extraktor ƒç≈ït (FeatureExtractor)
    fe = FeatureExtractor(return_array=False, impute_wavelet_only=True)
    fe.fit(rows)
    # Extrahuj ƒçrty a ponechaj len tie, ktor√© s√∫ relevantn√© pre fuzzy klasifik√°ciu
    X_df = fe.transform(rows)[FIS_FEATURES]
    X = X_df.to_numpy(float)

    # Ulo≈æ v√Ωsledky do cache (na bud√∫ce r√Ωchle naƒç√≠tanie)
    with open(pkl_path, "wb") as f:
        pickle.dump((X, np.asarray(y), FIS_FEATURES), f)
    return X, np.asarray(y), FIS_FEATURES


def load_ds1_ds2():
    """
        Naƒç√≠ta a spracuje tr√©novaciu (DS1) aj testovaciu (DS2) mno≈æinu z MIT-BIH datab√°zy.
        Vol√° funkciu build_ds pre obe mno≈æiny a z√°rove≈à vracia aj Pandas DataFrame verzie d√°t.

        Returns:
            X_tr (np.ndarray): Tr√©novacie pr√≠znaky
            y_tr (np.ndarray): Tr√©novacie triedy
            df_tr (pd.DataFrame): Tr√©novacie d√°ta ako DataFrame (na vizualiz√°ciu, MF gener√°ciu, atƒè.)
            X_te (np.ndarray): Testovacie pr√≠znaky
            y_te (np.ndarray): Testovacie triedy
            df_te (pd.DataFrame): Testovacie d√°ta ako DataFrame
        """
    # Naƒç√≠tanie tr√©novacej mno≈æiny (DS1)
    X_tr, y_tr, feat_names = build_ds(DS1, "ds1")
    df_tr = pd.DataFrame(X_tr, columns=feat_names)

    # Naƒç√≠tanie testovacej mno≈æiny (DS2)
    X_te, y_te, _ = build_ds(DS2, "ds2")
    df_te = pd.DataFrame(X_te, columns=feat_names)

    # Vr√°ti oba datasety vo form√°te ndarray aj ako DataFrame
    return X_tr, y_tr, df_tr, X_te, y_te, df_te


def create_fuzzy_mfs(feature, data, num_mfs):
    """
    Vytvor√≠ fuzzy ƒçlenitostn√© funkcie pre zvolen√∫ ƒçrtu (feature) pomocou c-means clusteringu.
    Fuzzy mno≈æiny s√∫ pomenovan√© podƒæa dom√©ny ƒçrty (napr. 'veƒæmi n√≠zka', 'n√≠zka', ...).

    Args:
        feature (str): N√°zov ƒçrty (napr. 'Heart_rate_bpm')
        data (np.ndarray): Hodnoty ƒçrty
        num_mfs (int): Poƒçet fuzzy mno≈æ√≠n (zvyƒçajne 5)

    Returns:
        universe (np.ndarray): Diskretizovan√Ω interval hodn√¥t
        mfs (dict): Slovn√≠k fuzzy mno≈æ√≠n {meno: ƒçlenitostn√° funkcia}
    """

    # Typy ƒç≈ït, ktor√© bud√∫ ma≈• pomenovan√© fuzzy mno≈æiny typu "n√≠zky-vysok√Ω"
    VALUE_FEATURES = ["P_amplitude", "T_amplitude", "Heart_rate_bpm", "R_amplitude"]
    INTERVAL_FEATURES = ["RR0_s", "RR1_s"]

    # Odstr√°≈à NaN hodnoty
    data = data[~np.isnan(data)]

    # Automatick√Ω clustering (c-means) pre urƒçenie stredov MF
    cntr, *_ = fuzz.cluster.cmeans(data.reshape(1, -1), c=num_mfs, m=2, error=0.005, maxiter=1000)
    cntr = np.sort(cntr.flatten())

    # Vytvor univerzum hodn√¥t (na v√Ωpoƒçet a vykreslenie MF)
    universe = np.linspace(np.min(data), np.max(data), 256)

    # Pomenovania mno≈æ√≠n podƒæa typu ƒçrty
    if feature in VALUE_FEATURES:
        mf_names = ["veƒæmi n√≠zka", "n√≠zka", "stredn√°", "vysok√°", "veƒæmi vysok√°"]
    elif feature in INTERVAL_FEATURES:
        mf_names = ["veƒæmi kr√°tky", "kr√°tky", "stredn√Ω", "dlh√Ω", "veƒæmi dlh√Ω"]
    else:
        mf_names = [f"mf{i+1}" for i in range(num_mfs)]

    mfs = {}

    # Generovanie jednotliv√Ωch MF
    for i, center in enumerate(cntr):
        if i == 0:
            a, b, c = np.min(data), center, cntr[i + 1]
        elif i == len(cntr) - 1:
            a, b, c = cntr[i - 1], center, np.max(data)
        else:
            a, b, c = cntr[i - 1], center, cntr[i + 1]

        if feature in VALUE_FEATURES:
            sigma = (c - a) / 4
            mfs[mf_names[i]] = fuzz.gaussmf(universe, b, sigma)
        else:
            mfs[mf_names[i]] = fuzz.trimf(universe, [a, b, c])

    return universe, mfs


def generate_all_mfs(df, normalize=False, num_mfs=5):
    """
    Vygeneruje v≈°etky fuzzy mno≈æiny (ƒçlenitostn√© funkcie) pre ka≈æd√∫ vstupn√∫ ƒçrtu v DataFrame.
    V√Ωsledky sa ukladaj√∫ do cache s√∫boru (.pkl), aby sa nemuseli opakovane poƒç√≠ta≈•.

    Args:
        df (pd.DataFrame): DataFrame s extrahovan√Ωmi pr√≠znakmi (napr. z DS1)
        normalize (bool): Ak je True, normalizuje ƒçrty do rozsahu [0, 1]
        num_mfs (int): Poƒçet fuzzy mno≈æ√≠n na jednu ƒçrtu (typicky 5)

    Returns:
        fuzzy_mfs (dict): Slovn√≠k fuzzy mno≈æ√≠n pre ka≈æd√∫ ƒçrtu.
                          Ka≈æd√Ω prvok obsahuje 'universe' a 'mfs'.
    """

    # Zvoƒæ n√°zov cache s√∫boru podƒæa toho, ƒçi sa pou≈æije normaliz√°cia
    fname = "fuzzy_mfs_norm.pkl" if normalize else "fuzzy_mfs_orig.pkl"
    path = CACHE / fname

    # Ak s√∫bor u≈æ existuje, naƒç√≠taj ulo≈æen√© fuzzy mno≈æiny
    if path.exists():
        with open(path, "rb") as f:
            return pickle.load(f)

    fuzzy_mfs = {}

    # Iteruj cez v≈°etky ƒçrty, pre ktor√© chceme generova≈• fuzzy mno≈æiny
    for feature in FIS_FEATURES:
        data = df[feature].values

        # Voliteƒæn√° normaliz√°cia ƒçrty do rozsahu [0, 1]
        if normalize:
            data = (data - np.min(data)) / (np.max(data) - np.min(data) + 1e-6)

        # Vytvor universe a fuzzy mno≈æiny pre dan√∫ ƒçrtu
        universe, mfs = create_fuzzy_mfs(feature, data, num_mfs=num_mfs)

        # Ulo≈æ do slovn√≠ka
        fuzzy_mfs[feature] = {"universe": universe, "mfs": mfs}

    # Ulo≈æ v√Ωsledn√© fuzzy mno≈æiny do cache s√∫boru
    with open(path, "wb") as f:
        pickle.dump(fuzzy_mfs, f)

    return fuzzy_mfs


def generate_rule(row, fuzzy_mfs):
    """
    Vytvor√≠ jedno fuzzy pravidlo pre dan√Ω √∫der (row) na z√°klade najviac aktivovan√Ωch fuzzy mno≈æ√≠n.
    Pre ka≈æd√∫ ƒçrtu sa zvol√≠ fuzzy mno≈æina (MF), ktor√° m√° najvy≈°≈°√≠ stupe≈à pr√≠slu≈°nosti.
    Pravidlo zah≈ï≈àa len tie MF, ktor√© maj√∫ aktiv√°ciu aspo≈à 0.5.

    Args:
        row (dict): Jedna vzorka (napr. EKG √∫der) vo forme slovn√≠ka s hodnotami ƒç≈ït a triedou ("label")
        fuzzy_mfs (dict): Slovn√≠k fuzzy mno≈æ√≠n pre ka≈æd√∫ ƒçrtu, obsahuje aj universe pre v√Ωpoƒçty

    Returns:
        tuple: (pravidlo vo forme zoznamu podmienok [(ƒçrta, n√°zov MF), ...], cieƒæov√° trieda)
    """

    # Zoznam podmienok pravidla (napr. [('RR0_s', 'stredn√Ω'), ('Heart_rate_bpm', 'vysok√°')])
    rule_conditions = []

    # Pre ka≈æd√∫ ƒçrtu (feature) z definovan√©ho zoznamu vstupn√Ωch pr√≠znakov
    for feature in FIS_FEATURES:
        # Z√≠skaj univerzum a fuzzy ƒçlenitostn√© funkcie (MFs) pre dan√∫ ƒçrtu
        universe = fuzzy_mfs[feature]['universe']
        mfs = fuzzy_mfs[feature]['mfs']

        # Vypoƒç√≠taj stupe≈à pr√≠slu≈°nosti (Œº) hodnoty z danej vzorky ku ka≈ædej fuzzy mno≈æine
        memberships = {
            mf_name: fuzz.interp_membership(universe, mf_curve, row[feature])
            for mf_name, mf_curve in mfs.items()
        }

        # Vyber MF s najvy≈°≈°ou mierou pr√≠slu≈°nosti
        best_mf, best_membership = max(memberships.items(), key=lambda x: x[1])

        # Ak je aktiv√°cia dostatoƒçne vysok√° (Œº ‚â• 0.5), pridaj do pravidla
        if best_membership >= 0.5:
            rule_conditions.append((feature, best_mf))

    # V√Ωstupom je tuple: pravidlo (podmienky) a trieda vzorky (napr. 'N', 'V', 'S', 'F')
    return tuple(rule_conditions), row["label"]


def build_rules(df, fuzzy_mfs):
    """
    Generuje fuzzy pravidl√° z datasetu. Ka≈æd√Ω riadok (√∫der EKG) je spracovan√Ω na fuzzy pravidlo
    pomocou najviac aktivovan√Ωch fuzzy mno≈æ√≠n. N√°sledne sa spoƒç√≠taj√∫ frekvencie v√Ωskytov,
    vypoƒç√≠ta sa podpora a spoƒæahlivos≈• (support a confidence), a filtruj√∫ sa len siln√© pravidl√°.

    Pravidl√° sa ukladaj√∫ do s√∫borov pre ƒèal≈°ie pou≈æitie.

    Args:
        df (pd.DataFrame): Vyv√°≈æen√Ω dataset s ƒçrtami a cieƒæovou triedou ("label")
        fuzzy_mfs (dict): Vygenerovan√© fuzzy ƒçlenitostn√© funkcie pre v≈°etky ƒçrty

    Returns:
        rules (list): Zoznam pravidiel vo form√°te (conds, label, confidence)
    """

    print("Prebieha generovanie fuzzy pravidiel...")

    # Konverzia dataframe na zoznam slovn√≠kov (ka≈æd√Ω riadok ako dict)
    rows = df.to_dict(orient="records")

    # Paraleln√© generovanie pravidiel z jednotliv√Ωch √∫derov
    results = Parallel(n_jobs=mp.cpu_count(), backend="loky")(
        delayed(generate_rule)(row, fuzzy_mfs) for row in rows
    )

    # Spoƒç√≠tanie frekvenci√≠ rovnak√Ωch pravidiel (vr√°tane triedy)
    rule_counts = Counter(results)

    # Celkov√Ω poƒçet v√Ωskytov pravidla bez ohƒæadu na triedu (pre confidence)
    rule_totals = Counter([r[0] for r in results])

    rules = []

    # Iteruj cez v≈°etky kombin√°cie (podmienky, trieda)
    for (conds, label), count in rule_counts.items():
        support = count  # poƒçet pr√≠padov, ktor√© zodpovedaj√∫ pravidlu
        total = rule_totals[conds]  # v≈°etky pr√≠pady s rovnak√Ωmi podmienkami
        confidence = support / total  # spoƒæahlivos≈• pravidla

        # Nastavenie minim√°lnych po≈æiadaviek na kvalitu pravidla podƒæa triedy
        if label in ['V', 'S']:
            min_confidence = 0.8
            min_support = 6
        elif label == 'F':
            min_confidence = 0.9
            min_support = 12
        else:  # trieda 'N'
            min_confidence = 0.9
            min_support = 10

        # Ak pravidlo spln√≠ podmienky, pridaj ho
        if support >= min_support and confidence >= min_confidence:
            rules.append((conds, label, confidence))

    # V√Ωpis pravidiel v textovej forme (na konzolu aj do s√∫boru)
    rule_text = [
        " AND ".join(f"{f}:{m}" for f, m in conds) + f" => {label} (conf: {conf:.2f})"
        for conds, label, conf in rules
    ]

    # Ulo≈æenie pravidiel do s√∫boru .txt (ƒæahko ƒçitateƒæn√Ω form√°t)
    with open("fuzzy_rules.txt", "w", encoding="utf-8") as f:
        f.write("Fuzzy pravidl√° (podmienky => trieda):\n\n")
        for line in rule_text:
            f.write(line + "\n")

    # Ulo≈æenie pravidiel do s√∫boru .pkl (na neskor√© naƒç√≠tanie modelu)
    with open("fuzzy_rules.pkl", "wb") as f:
        pickle.dump(rules, f)

    print(f"‚úÖ Bolo extrahovan√Ωch {len(rules)} fuzzy pravidiel.")
    print(f"üìÅ Pravidl√° ulo≈æen√© do: 'fuzzy_rules.txt' a 'fuzzy_rules.pkl'")

    return rules

def limit_rules_by_class(rules, max_per_class=300):
    """
    Obmedz√≠ maxim√°lny poƒçet fuzzy pravidiel pre ka≈æd√∫ v√Ωstupn√∫ triedu (N, S, V, F).
    Pravidl√° s√∫ najprv zoraden√© podƒæa spoƒæahlivosti (confidence) a n√°sledne sa vyberie
    len najspoƒæahlivej≈°√≠ch N pravidiel na triedu.

    Args:
        rules (list): Zoznam fuzzy pravidiel vo form√°te (podmienky, trieda, confidence)
        max_per_class (int): Predvolen√Ω limit pre triedy, ak nie je definovan√Ω v slovn√≠ku

    Returns:
        pruned (list): Zredukovan√Ω zoznam pravidiel s aplikovan√Ωmi limitmi
    """

    # Vlastn√© maxim√°lne poƒçty pravidiel pre jednotliv√© triedy
    max_per_class_dict = {
        "N": 300,   # Norm√°lne √∫dery ‚Äì najviac pravidiel
        "S": 300,   # Supraventrikul√°rne √∫dery
        "V": 200,   # Ventrikul√°rne √∫dery
        "F": 100    # Fusion beats ‚Äì zriedkav√©
    }

    # Zoskupenie pravidiel podƒæa cieƒæovej triedy
    rules_by_class = defaultdict(list)

    # Zoradenie pravidiel podƒæa confidence zostupne
    for conds, cls, conf in sorted(rules, key=lambda x: -x[2]):
        # Pridaj pravidlo len ak e≈°te nedosiahneme limit pre triedu
        if len(rules_by_class[cls]) < max_per_class_dict.get(cls, max_per_class):
            rules_by_class[cls].append((conds, cls, conf))

    # Spojenie v≈°etk√Ωch pravidiel do jedn√©ho zoznamu
    pruned = [rule for group in rules_by_class.values() for rule in group]

    print(f" Po aplikovan√≠ limitu na poƒçet pravidiel pre triedu zost√°va {len(pruned)} pravidiel.")
    return pruned


from itertools import product


def mamdani_defuzzification(rule_scores, label_universe, mf_width=0.7):
    """
    Vykon√° defuzzifik√°ciu pomocou Mamdaniho met√≥dy s trojuholn√≠kov√Ωmi MF a met√≥dou 'SOM'
    (Smallest of Maximum), ktor√° je vhodn√° pre klasifikaƒçn√© √∫lohy so zreteƒæn√Ωm v√Ωberom triedy.

    Args:
        rule_scores (dict): Slovn√≠k s aktiv√°ciami v√Ωstupn√Ωch tried, napr. {'N': 0.7, 'S': 0.5}.
        label_universe (np.ndarray): Diskretizovan√Ω interval hodn√¥t (napr. np.linspace(1, 4, 100)).
        mf_width (float): ≈†√≠rka v√Ωstupn√Ωch fuzzy mno≈æ√≠n. Typick√° hodnota je 0.7.

    Returns:
        str: Predikovan√° v√Ωstupn√° trieda ako re≈•azec ('N', 'S', 'V', alebo 'F').
    """

    # Inicializ√°cia v√Ωstupn√©ho fuzzy vektora ‚Äì reprezentuje agregovan√Ω v√Ωstup
    aggregated = np.zeros_like(label_universe)

    # Pre ka≈æd√∫ v√Ωstupn√∫ triedu (N, S, V, F) s nenulovou aktiv√°ciou
    for label, membership_value in rule_scores.items():
        # Urƒç stred v√Ωstupnej MF na ƒç√≠selnej osi (1 pre 'N', 2 pre 'S', atƒè.)
        center = LABELS.index(label) + 1

        # Vytvor trojuholn√≠kov√∫ fuzzy mno≈æinu pre t√∫to triedu
        label_mf = fuzz.trimf(
            label_universe,
            [center - mf_width, center, center + mf_width]
        )

        # Vypoƒç√≠taj v√Ωstup pravidla (AND medzi aktiv√°ciou a MF), n√°sledne agreguj (MAX)
        np.maximum(aggregated, np.fmin(membership_value, label_mf), out=aggregated)

    # Defuzzifikuj v√Ωsledn√Ω fuzzy v√Ωstup pomocou met√≥dy SOM (Smallest of Maximum)
    result = fuzz.defuzz(label_universe, aggregated, 'som')

    # Zaokr√∫hli v√Ωsledok na index a zabezpeƒç, aby bol v rozsahu tried
    label_idx = int(np.clip(np.round(result) - 1, 0, len(LABELS) - 1))

    # Vr√°≈• n√°zov triedy podƒæa indexu (napr. 'N', 'S', ...)
    return LABELS[label_idx]

def fast_fuzzy_predict(row, fuzzy_mfs, rules, mf_width=0.7):
    """
    Vykon√° inferenciu (predikciu) pre jednu vzorku pomocou fuzzy pravidiel a Mamdaniho defuzzifik√°cie.

    Args:
        row (list or np.ndarray): Jedna vzorka s hodnotami ƒç≈ït (napr. EKG √∫der)
        fuzzy_mfs (dict): Slovn√≠k fuzzy mno≈æ√≠n pre ka≈æd√∫ ƒçrtu
        rules (list): Zoznam fuzzy pravidiel vo form√°te (conds, label, confidence)
        mf_width (float): ≈†√≠rka v√Ωstupn√Ωch v√Ωstupn√Ωch MF pri defuzzifik√°cii

    Returns:
        predicted_label (str): Predikovan√° trieda ('N', 'S', 'V', 'F')
        applied_rule_str (str): Reprezent√°cia najlep≈°ie aktivovan√©ho pravidla pre dan√∫ triedu
    """

    # Uchov√°va sk√≥re pre ka≈æd√∫ v√Ωstupn√∫ triedu (agreg√°cia aktivovan√Ωch pravidiel)
    rule_scores = defaultdict(float)

    # Uklad√° najlep≈°ie aktivovan√© pravidlo pre ka≈æd√∫ triedu
    best_rules = {}

    # Prech√°dzaj v≈°etky pravidl√° z pravidlovej b√°zy
    for conds, label, weight in rules:
        # Z√≠skaj mieru pr√≠slu≈°nosti pre ka≈æd√∫ podmienku pravidla
        memberships = [
            fuzz.interp_membership(
                fuzzy_mfs[feature]['universe'],        # univerzum ƒçrty
                fuzzy_mfs[feature]['mfs'][mf],         # ƒçlenitostn√° funkcia MF
                row[FIS_FEATURES.index(feature)]       # hodnota ƒçrty zo vzorky
            )
            for feature, mf in conds
        ]

        # Vypoƒç√≠taj sk√≥re pravidla: confidence * min(Œº1, Œº2, ..., Œºn)
        score = weight * min(memberships)

        # Ak sk√≥re je vy≈°≈°ie ako doteraj≈°ie pre dan√Ω label, aktualizuj
        if score > rule_scores[label]:
            rule_scores[label] = score
            best_rules[label] = (conds, label, score)

    # Defuzzifik√°cia ‚Äì v√Ωber v√Ωslednej triedy podƒæa agregovan√Ωch sk√≥re
    label_universe = np.linspace(1, len(LABELS), 100)
    predicted_label = mamdani_defuzzification(rule_scores, label_universe, mf_width=mf_width)

    # Z√≠skaj najlep≈°ie pravidlo, ktor√© prispelo k predikcii
    main_rule = best_rules.get(predicted_label, None)

    # Ak existuje, vytvor jeho textov√∫ reprezent√°ciu
    if main_rule:
        conds, label, score = main_rule
        applied_rule_str = " AND ".join([f"{f}:{m}" for f, m in conds]) + f" => {label} (sk√≥re: {score:.3f})"
    else:
        applied_rule_str = "N/A"

    return predicted_label, applied_rule_str



def predict_fast_batch(X_test, fuzzy_mfs, rules):
    """
    Paralelne vykon√° fuzzy inferenciu pre v≈°etky vzorky v testovacom datasete
    pomocou optimalizovanej funkcie fast_fuzzy_predict.

    Args:
        X_test (np.ndarray): Testovacia mno≈æina (ka≈æd√Ω riadok = jedna vzorka)
        fuzzy_mfs (dict): Slovn√≠k fuzzy mno≈æ√≠n pre v≈°etky ƒçrty
        rules (list): Zoznam fuzzy pravidiel vo form√°te (podmienky, label, confidence)

    Returns:
        predictions (tuple): N-tica predikovan√Ωch tried (napr. 'N', 'V', ...)
        applied_rules (tuple): N-tica textov√Ωch reprezent√°ci√≠ najlep≈°√≠ch aplikovan√Ωch pravidiel
    """

    # ‚ö° Paraleln√° inferencia pre ka≈æd√∫ vzorku pomocou joblib.Parallel
    results = Parallel(n_jobs=mp.cpu_count(), backend='threading')(
        delayed(fast_fuzzy_predict)(row, fuzzy_mfs, rules)
        for row in tqdm(X_test, desc="Fast fuzzy inference")
    )

    # Rozdelenie v√Ωsledkov: [(label1, rule1), (label2, rule2), ...] ‚Üí dve oddelen√© n-tice
    predictions, applied_rules = zip(*results)

    return predictions, applied_rules




def fuzzy_pipeline(X_train, y_train, X_test, y_test):
    """
    Kompletn√Ω fuzzy klasifikaƒçn√Ω pipeline:
    - Vyv√°≈æi tr√©novacie d√°ta
    - Vygeneruje fuzzy mno≈æiny a pravidl√°
    - Vykon√° inferenciu na testovacej mno≈æine
    - Vyhodnot√≠ model metrikami a ulo≈æ√≠ v√Ωsledky

    Args:
        X_train (np.ndarray): Tr√©novacie ƒçrty (napr. z DS1)
        y_train (np.ndarray): Triedy pre tr√©novacie d√°ta
        X_test (np.ndarray): Testovacie ƒçrty (napr. z DS2)
        y_test (np.ndarray): Triedy pre testovacie d√°ta
    """

    # 1. Vyv√°≈æenie datasetu pomocou under- a oversamplingu
    df_bal = balance_datav2(X_train, y_train)
    df_bal.to_csv("balanced_DS1_for_both.csv", index=False)
    print("Vyv√°≈æen√° d√°tov√° mno≈æina bola ulo≈æen√° do s√∫boru 'balanced_DS1_for_both.csv'")

    # 2. Generovanie fuzzy mno≈æ√≠n (ƒçlenitostn√Ωch funkci√≠) pre v≈°etky ƒçrty
    fuzzy_mfs = generate_all_mfs(df_bal, normalize=False)
    plot_and_save_fuzzy_mfs(fuzzy_mfs, FIS_FEATURES)

    # 3. Vizualiz√°cia aktiv√°cie fuzzy mno≈æ√≠n pre jeden konkr√©tny √∫der
    beat_features = X_test[0]
    plot_single_beat_memberships(beat_features, fuzzy_mfs, "Heart_rate_bpm")

    # 4. Generovanie fuzzy pravidiel + orezanie na max. poƒçet pravidiel na triedu
    rules = build_rules(df_bal, fuzzy_mfs)
    rules = limit_rules_by_class(rules, max_per_class=300)

    # 5. Odstr√°≈à pravidl√° pre triedy, ktor√© nie s√∫ v LABELS
    rules = [r for r in rules if r[1] in LABELS]

    # 6. Vizualiz√°cia v√Ωstupn√Ωch fuzzy mno≈æ√≠n pre v√Ωstupn√∫ premenn√∫
    plot_output_mfs(LABELS, mf_type='trimf', width=0.7)

    # 7. V√Ωpis poƒçtu pravidiel pre ka≈æd√∫ triedu
    rule_dist = defaultdict(int)
    for _, label, _ in rules:
        rule_dist[label] += 1
    print("Rozdelenie pravidiel podƒæa tried:", dict(rule_dist))

    # 8. Paraleln√° fuzzy inferencia nad testovacou mno≈æinou
    y_pred, applied_rules = predict_fast_batch(X_test, fuzzy_mfs, rules)

    # 9. Vytvor dataframe s detailn√Ωmi predikciami a pravidlami
    detailed_results = pd.DataFrame(X_test, columns=FIS_FEATURES)
    detailed_results["True_Label"] = y_test
    detailed_results["Predicted_Label"] = y_pred
    detailed_results["Rule"] = applied_rules
    detailed_results.to_csv("detailed_predictions.csv", index=False)

    # 10. V√Ωpis klasifikaƒçnej spr√°vy a v√Ωpoƒçty metr√≠k
    print("\nV√Ωstup klasifikaƒçnej spr√°vy:")
    report = classification_report(y_test, y_pred, digits=3, zero_division=0)
    macro_f1 = f1_score(y_test, y_pred, average="macro")
    mcc = matthews_corrcoef(y_test, y_pred)

    # V√Ωpoƒçet ROC-AUC (pre multiklasy)
    y_test_bin = label_binarize(y_test, classes=LABELS)
    y_pred_bin = label_binarize(y_pred, classes=LABELS)
    roc_auc = roc_auc_score(y_test_bin, y_pred_bin, average="macro", multi_class="ovr")

    #  V√Ωpis do konzoly
    print(report)
    print("Macro-F1:", macro_f1)
    print("MCC:", mcc)
    print("ROC-AUC:", roc_auc)

    # 11. Ulo≈æenie metr√≠k do textov√©ho s√∫boru
    with open("fuzzy_report_parallel.txt", "w") as f:
        f.write(report)
        f.write(f"\nMacro-F1: {macro_f1:.4f}")
        f.write(f"\nMCC: {mcc:.4f}")
        f.write(f"\nROC-AUC: {roc_auc:.4f}")

    # 12. Konf√∫zna matica
    cm = confusion_matrix(y_test, y_pred, labels=LABELS)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=LABELS, yticklabels=LABELS)
    plt.xlabel('Predikovan√° trieda')
    plt.ylabel('Skutoƒçn√° trieda')
    plt.title('Konf√∫zna matica')
    plt.tight_layout()
    plt.savefig("confusion_matrix.png", dpi=300)
    plt.close()

    print("Confusion matrix ulo≈æen√° ako 'confusion_matrix.png'")





def balance_datav2(X, y):
    """
    Vyv√°≈æi d√°tov√∫ mno≈æinu v dvoch krokoch:
    1. Odstr√°ni triedu 'Q', ktor√° nie je zahrnut√° vo fuzzy klasifik√°cii.
    2. Pou≈æije RandomUnderSampler na zn√≠≈æenie poƒçtu dominantnej triedy 'N'.
    3. Pou≈æije BorderlineSMOTE na syntetick√© doplnenie men≈°inov√Ωch tried.

    Args:
        X (np.ndarray): Matica vstupn√Ωch ƒç≈ït (napr. EKG pr√≠znaky)
        y (np.ndarray): Zodpovedaj√∫ce triedy (napr. 'N', 'V', 'S', ...)

    Returns:
        df_bal (pd.DataFrame): Vyv√°≈æen√° d√°tov√° mno≈æina vo forme DataFrame (vr√°tane stƒ∫pca 'label')
    """

    print("Vyva≈æovanie d√°tovej mno≈æiny...")

    # 1. Imput√°cia ch√Ωbaj√∫cich hodn√¥t (medianom)
    imputer = SimpleImputer(strategy="median")
    X_imp = imputer.fit_transform(X)

    # 2. Odstr√°nenie vzoriek s triedou 'Q', ktor√© sa nezapoƒç√≠tavaj√∫ do klasifik√°cie
    mask = y != "Q"
    X_filtered, y_filtered = X_imp[mask], y[mask]

    # 3. Undersampling: obmedz poƒçet vzoriek triedy 'N' na max. 4000
    rus = RandomUnderSampler(sampling_strategy={'N': 4000}, random_state=42)
    X_under, y_under = rus.fit_resample(X_filtered, y_filtered)

    # 4. Oversampling: syntetick√© generovanie vzoriek pre ostatn√© triedy pomocou BorderlineSMOTE
    smote = BorderlineSMOTE(sampling_strategy='not majority', random_state=42)
    X_bal, y_bal = smote.fit_resample(X_under, y_under)

    # 5. Vytvorenie DataFrame a pripojenie cieƒæov√©ho stƒ∫pca 'label'
    df_bal = pd.DataFrame(X_bal, columns=FIS_FEATURES)
    df_bal["label"] = y_bal

    # V√Ωpis v√Ωsledn√©ho rozdelenia tried po vyv√°≈æen√≠
    print("Rozdelenie tried po vyv√°≈æen√≠:", Counter(df_bal["label"]))
    print("Po balansovan√≠:")
    return df_bal

def plot_and_save_fuzzy_mfs(fuzzy_mfs, features):
    """
    Pre ka≈æd√∫ ƒçrtu v zozname vygeneruje graf fuzzy ƒçlenitostn√Ωch funkci√≠ (MF)
    a ulo≈æ√≠ ho ako PNG s√∫bor do zvolen√©ho v√Ωstupn√©ho adres√°ra.

    Args:
        fuzzy_mfs (dict): Slovn√≠k fuzzy mno≈æ√≠n pre ka≈æd√∫ ƒçrtu.
                          Obsahuje 'universe' a 'mfs' (n√°zov MF ‚Üí funkcia).
        features (list): Zoznam n√°zvov ƒç≈ït, pre ktor√© sa maj√∫ MF vizualizova≈•.
    """

    for feature in features:
        # Z√≠skanie diskretizovan√©ho rozsahu hodn√¥t (x-ov√° os)
        universe = fuzzy_mfs[feature]['universe']

        # Z√≠skanie fuzzy mno≈æ√≠n pre dan√∫ ƒçrtu
        mfs = fuzzy_mfs[feature]['mfs']

        # Vytvorenie grafu
        plt.figure(figsize=(8, 4))

        # Pre ka≈æd√∫ fuzzy mno≈æinu vykresli pr√≠slu≈°nostn√∫ funkciu
        for mf_name, mf_curve in mfs.items():
            plt.plot(universe, mf_curve, label=mf_name)

        # Popisy a ≈°t√Ωl grafu
        plt.title(f'Fuzzy Membership Functions - {feature}', fontsize=14)
        plt.xlabel(f'Hodnoty {feature}')
        plt.ylabel('Pr√≠slu≈°nos≈• (Œº)')
        plt.legend(loc='upper right')
        plt.grid(True)
        plt.tight_layout()

        # Vytvor v√Ωstupn√∫ cestu a ulo≈æ graf
        plot_path = PLOTS_DIR / f"{feature}_mfs.png"
        plt.savefig(plot_path, dpi=300)
        plt.close()

        print(f"MF pre '{feature}' ulo≈æen√© do: {plot_path}")


def plot_output_mfs(labels=['N', 'S', 'F', 'V'], mf_type='trimf', width=0.5):
    """
    Vytvor√≠ graf fuzzy mno≈æ√≠n (ƒçlenitostn√Ωch funkci√≠) pre v√Ωstupn√∫ premenn√∫ "Class".
    Triedy s√∫ umiestnen√© na numerickej osi 1, 2, 3, 4 a ka≈æd√° m√° svoju fuzzy mno≈æinu.

    Args:
        labels (list): Zoznam tried, pre ktor√© sa bud√∫ tvori≈• fuzzy mno≈æiny.
                       Ka≈æd√° trieda bude reprezentovan√° na svojej ƒç√≠selnej poz√≠cii.
        mf_type (str): Typ ƒçlenitostnej funkcie ('trimf', 'trapmf', 'gaussmf').
        width (float): Parametrick√° ≈°√≠rka fuzzy mno≈æiny (ovplyv≈àuje prekrytie).
    """

    # Vytvor univerzum hodn√¥t pre v√Ωstupn√∫ premenn√∫ (napr. od 1.0 po 4.0)
    label_universe = np.linspace(1, len(labels), 500)

    # Inicializuj graf
    plt.figure(figsize=(8, 4))

    # Pre ka≈æd√∫ triedu vytvor pr√≠slu≈°n√∫ fuzzy mno≈æinu
    for idx, label in enumerate(labels):
        center = idx + 1  # napr. 'N' ‚Üí 1, 'S' ‚Üí 2, atƒè.

        # Vytvor ƒçlenitostn√∫ funkciu podƒæa po≈æadovan√©ho typu
        if mf_type == 'trimf':
            mf_curve = fuzz.trimf(label_universe, [center - width, center, center + width])
        elif mf_type == 'trapmf':
            half_width = width / 2
            mf_curve = fuzz.trapmf(label_universe,
                                   [center - width, center - half_width, center + half_width, center + width])
        elif mf_type == 'gaussmf':
            mf_curve = fuzz.gaussmf(label_universe, center, width)
        else:
            raise ValueError("Nepodporovan√Ω typ MF.")

        # Vykresli fuzzy mno≈æinu do grafu
        plt.plot(label_universe, mf_curve, label=label)

    # Nastavenie popisov grafu
    plt.title('Fuzzy v√Ωstupn√© mno≈æiny - V√Ωstupn√° premenn√° "Class"', fontsize=14)
    plt.xlabel('V√Ωstupn√° premenn√° Class (numericky)')
    plt.ylabel('Pr√≠slu≈°nos≈• (Œº)')
    plt.xticks(range(1, len(labels) + 1), range(1, len(labels) + 1))
    plt.legend()
    plt.grid(True)
    plt.tight_layout()

    # Ulo≈æenie grafu do s√∫boru
    plot_path = PLOTS_DIR / f"output_variable_mfs.png"
    plt.savefig(plot_path, dpi=300)
    plt.close()

    print(f"V√Ωstupn√© MF ulo≈æen√© do: {plot_path}")


def plot_single_beat_memberships(beat_features, fuzzy_mfs, feature_name="Heart_rate_bpm"):
    """
    Vizualizuje fuzzy ƒçlenitostn√© funkcie pre jednu ƒçrtu a oznaƒç√≠,
    ako silno je hodnota konkr√©tneho √∫deru (beat) priraden√° ku ka≈ædej mno≈æine.

    Args:
        beat_features (list or np.ndarray): Vektor ƒç≈ït pre jeden √∫der
        fuzzy_mfs (dict): Slovn√≠k fuzzy mno≈æ√≠n s 'universe' a 'mfs' pre ka≈æd√∫ ƒçrtu
        feature_name (str): N√°zov ƒçrty, ktor√∫ chceme analyzova≈• (napr. 'Heart_rate_bpm')
    """

    # Z√≠skaj hodnotu danej ƒçrty z beat_features
    beat_value = beat_features[FIS_FEATURES.index(feature_name)]

    # Z√≠skaj univerzum a ƒçlenitostn√© funkcie pre dan√∫ ƒçrtu
    universe = fuzzy_mfs[feature_name]['universe']
    mfs = fuzzy_mfs[feature_name]['mfs']

    # Priprav graf
    plt.figure(figsize=(10, 6))
    memberships = {}

    # Definovan√© farby pre jednotliv√© fuzzy mno≈æiny
    colors = ["#1f77b4", "#ff7f0e", "#2ca02c", "#d62728", "#9467bd"]

    # Pre ka≈æd√∫ fuzzy mno≈æinu vykresli krivku a vypoƒç√≠taj aktiv√°ciu pre konkr√©tny beat_value
    for (mf_name, mf_curve), color in zip(mfs.items(), colors):
        plt.plot(universe, mf_curve, label=mf_name, color=color)

        # V√Ωpoƒçet stup≈àa pr√≠slu≈°nosti
        membership = fuzz.interp_membership(universe, mf_curve, beat_value)
        memberships[mf_name] = membership

        # Vizualiz√°cia bodu aktiv√°cie na krivke MF
        plt.plot(beat_value, membership, 'o', markersize=8, color=color)

    # Zvisl√° ƒçiara zn√°zor≈àuj√∫ca hodnotu beat_value na osi x
    plt.axvline(x=beat_value, color='k', linestyle='--', label=f'Hodnota beat: {beat_value:.2f}')

    # Popis grafu
    plt.title(f'Aktiv√°cia fuzzy mno≈æ√≠n pre {feature_name}')
    plt.xlabel(f'Hodnoty ƒçrty: {feature_name}')
    plt.ylabel('Stupe≈à pr√≠slu≈°nosti (Œº)')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()

    # Ulo≈æenie grafu do s√∫boru
    plot_path = PLOTS_DIR / f"single_beat_{feature_name}_activation.png"
    plt.savefig(plot_path, dpi=300)
    plt.close()

    # V√Ωpis inform√°ci√≠ o pr√≠slu≈°nosti do konzoly
    print(f"Graf aktiv√°cie ulo≈æen√Ω ako '{plot_path}'")
    print(f"\nStupne pr√≠slu≈°nosti hodnoty {beat_value:.2f} k fuzzy mno≈æin√°m pre '{feature_name}':")
    for mf_name, membership in memberships.items():
        print(f" - {mf_name}: {membership:.3f}")

def main():
    """
    Hlavn√° vstupn√° funkcia skriptu. Spust√≠ naƒç√≠tanie d√°t, predspracovanie
    a n√°sledne cel√Ω fuzzy klasifikaƒçn√Ω pipeline.
    """

    # Potlaƒçenie varovan√≠ typu RuntimeWarning (napr. pri v√Ωpoƒçtoch s NaN)
    warnings.filterwarnings("ignore", category=RuntimeWarning)

    # 1. Naƒç√≠tanie tr√©novacej a testovacej mno≈æiny z MIT-BIH datab√°zy
    X_tr, y_tr, _, X_te, y_te, _ = load_ds1_ds2()

    # 2. Imput√°cia ch√Ωbaj√∫cich hodn√¥t (napr. NaN) pomocou medi√°nu
    imputer = SimpleImputer(strategy='median')
    X_tr = imputer.fit_transform(X_tr)
    X_te = imputer.transform(X_te)

    # 3. Spustenie kompletn√©ho fuzzy pipeline (generovanie MF, pravidiel, inferencia, vyhodnotenie)
    fuzzy_pipeline(X_tr, y_tr, X_te, y_te)

# Spustenie skriptu, ak je sp√∫≈°≈•an√Ω priamo
if __name__ == "__main__":
    main()

